Structure

{
  "sae_id": "google/gemma-scope-9b-pt-res/layer_30/width_16k/average_l0_120",
  "features": [
    {
      "feature_id": 0,
      "explanations": [
        {
          "text": "Phrases or words that introduce a question...",
          "llm_explainer": "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
          "pairwise_semantic_similarity": [
            {
              "llm_explainer": "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
              "cosine_similarity": 0.93
            }
          ],
          "scores": {
            "fuzz": 0.75,
            "detection": 0.71,
            "embedding": 0.57
          }
        }
      ]
    }
  ]
}

Key Explanations

sae_id - Identifier of the Sparse Autoencoder model

features - List of all 700 features (IDs 0-699)

feature_id - Unique number for each feature

explanations - List of explanations from different AI models (or null if no data)

text - Natural language explanation of what the feature detects

llm_explainer - Name of the AI model that generated this explanation

pairwise_semantic_similarity - How similar this explanation is to others

cosine_similarity - Similarity score between 0 and 1 (higher = more similar)

scores - Interpretability scores (https://arxiv.org/abs/2410.13928)

fuzz - Fuzzing test score (0-1)

detection - Detection test score (0-1)

embedding - Embedding similarity score (0-1)
